library(roxygen2)
roxygen2::roxygenize
?lr
getwd()
roxygen2::roxygenize
devtools::document()
devtools::document()
?lr
data(mtcars)
data <- train_test_sampling(mtcars, "am", train_prop=0.75, return_data=TRUE, seed=123)
train<-data$train
result <- lr(formula = am ~ mpg + hp + wt, data = train)
print(result$beta_optimized)
print(result$confusion_matrix
)
data(iris)
# Create a binary dependent variable that includes only species 'setosa' and 'versicolor'
iris_binary <- iris[iris$Species %in% c("setosa", "versicolor"), ]
iris_binary$Species <- factor(iris_binary$Species)
# Fit the model
result <- lr(Species ~ Sepal.Length + Sepal.Width, data = iris_binary)
print(result$beta_optimized)
X <- iris_binary[, c("Sepal.Length", "Sepal.Width")]
y <- as.numeric(iris_binary$Species) - 1
result <- lr(X = X, y = y, B = 50, alpha = 0.01)
print(result$beta_optimized)
?predict_new
data(mtcars)
model<-lr(am~hp+mpg+wt, data=mtcars, B=50, alpha=0.05)
# For this example we will generate random data for variables 'hp', 'mpg', and 'wt'.
n<-10
hp<-round(runif(n, min(mtcars$hp), max(mtcars$hp)),1)
mpg<-round(runif(n, min(mtcars$mpg), max(mtcars$mpg)),1)
wt<-round(runif(n, min(mtcars$wt), max(mtcars$wt)),1)
new_data<-data.frame(
hp=hp,
wt=wt,
mpg=mpg)
#Now we use the function to predict the outcome
new_predictions<-predict_new(data=new_data, model=model, threshold=0.5)
head(new_predictions)
data(iris)
iris_binary <- iris[iris$Species %in% c("setosa", "versicolor"), ]
iris_binary$Species <- factor(iris_binary$Species)
# Fit a logistic regression model using function \code{lr}
model <- lr(Species ~ Sepal.Length + Sepal.Width, data = iris_binary)
# For this example we will generate new random data for variables 'Sepal.Length' and 'Sepal.Width'.
n<-10
Sepal.Length<-round(runif(n, min(iris_binary$Sepal.Length), max(iris_binary$Sepal.Length)), 1)
Sepal.Width<-round(runif(n, min(iris_binary$Sepal.Width), max(iris_binary$Sepal.Width)), 1)
new_data<-data.frame(
Sepal.Length=Sepal.Length,
Sepal.Width=Sepal.Width)
# Predict outcomes on new data
predictions <- predict_new(data = new_data, model = model, threshold=0.5)
head(predictions)
?predict_test
split_data <- train_test_sampling(mtcars, dependent_var = 'am', train_prop = 0.75, return_data = TRUE, seed = 123)
train_data<-split_data$train
test_data<-split_data$test
# For this example we will create a model object using function \code{lr} using the training data, and variable am as the dependent variable.
lrcars<-lr(am~hp+mpg+wt, data=train_data, B=50, alpha=0.05)
# Now that we have created a logistic regression model with the training data, we test the performance of the model in new unseen data stored in the test data set.
results<-predict_test(test_data, lrcars, "am")
head(results)
data(iris)
iris_binary <- iris[iris$Species %in% c("setosa", "versicolor"), ]
iris_binary$Species <- factor(iris_binary$Species)
# Create a training and test sets from original data using function \code{train_test_sampling}
iris_binary_samples<-train_test_sampling(iris_binary, dependent_var="Species", training_prop=0.75, return_data=TRUE, seed=123)
?train_test_sampling
devtools::document()
?predict_test
data(iris)
iris_binary <- iris[iris$Species %in% c("setosa", "versicolor"), ]
iris_binary$Species <- factor(iris_binary$Species)
# Create a training and test sets from original data using function \code{train_test_sampling}
iris_binary_samples<-train_test_sampling(iris_binary, dependent_var="Species", train_prop=0.75, return_data=TRUE, seed=123)
iris_train<-iris_binary_samples$train
iris_test<-iris_binary_sample$test
devtools::document()
?predict_test
data(iris)
iris_binary <- iris[iris$Species %in% c("setosa", "versicolor"), ]
iris_binary$Species <- factor(iris_binary$Species)
# Create a training and test sets from original data using function \code{train_test_sampling}
iris_binary_samples<-train_test_sampling(iris_binary, dependent_var="Species", train_prop=0.75, return_data=TRUE, seed=123)
iris_train<-iris_binary_samples$train
iris_test<-iris_binary_samples$test
# Fit a logistic regression model using function \code{lr}
model <- lr(Species ~ Sepal.Length + Sepal.Width, data = iris_train)
# Predict outcomes on test data
predictions <- predict_test(new_data = iris_test, model = model, dependent_variable_col = "Species")
head(predictions)
split_data <- train_test_sampling(mtcars, dependent_var = 'am', train_prop = 0.75, return_data = TRUE, seed = 123)
train_data<-split_data$train
test_data<-split_data$test
# For this example we will create a model object using function \code{lr} using the training data, and variable am as the dependent variable.
lrcars<-lr(am~hp+mpg+wt, data=train_data, B=50, alpha=0.05)
# Now that we have created a logistic regression model with the training data, we test the performance of the model in new unseen data stored in the test data set.
results<-predict_test(test_data, lrcars, "am")
head(results)
?predict_new
data(iris)
iris_binary <- iris[iris$Species %in% c("setosa", "versicolor"), ]
iris_binary$Species <- factor(iris_binary$Species)
# Fit a logistic regression model using function \code{lr}
model <- lr(Species ~ Sepal.Length + Sepal.Width, data = iris_binary)
# For this example we will generate new random data for variables 'Sepal.Length' and 'Sepal.Width'.
n<-10
Sepal.Length<-round(runif(n, min(iris_binary$Sepal.Length), max(iris_binary$Sepal.Length)), 1)
Sepal.Width<-round(runif(n, min(iris_binary$Sepal.Width), max(iris_binary$Sepal.Width)), 1)
new_data<-data.frame(
Sepal.Length=Sepal.Length,
Sepal.Width=Sepal.Width)
# Predict outcomes on new data
predictions <- predict_new(data = new_data, model = model, threshold=0.5)
head(predictions)
data(mtcars)
model<-lr(am~hp+mpg+wt, data=mtcars, B=50, alpha=0.05)
# For this example we will generate random data for variables 'hp', 'mpg', and 'wt'.
n<-10
hp<-round(runif(n, min(mtcars$hp), max(mtcars$hp)),1)
mpg<-round(runif(n, min(mtcars$mpg), max(mtcars$mpg)),1)
wt<-round(runif(n, min(mtcars$wt), max(mtcars$wt)),1)
new_data<-data.frame(
hp=hp,
wt=wt,
mpg=mpg)
#Now we use the function to predict the outcome
new_predictions<-predict_new(data=new_data, model=model, threshold=0.5)
head(new_predictions)
?lr
data(mtcars)
data <- train_test_sampling(mtcars, "am", train_prop=0.75, return_data=TRUE, seed=123)
train<-data$train
result <- lr(formula = am ~ mpg + hp + wt, data = train)
print(result$beta_optimized)
print(result$confusion_matrix)
data(iris)
# Create a binary dependent variable that includes only species 'setosa' and 'versicolor'
iris_binary <- iris[iris$Species %in% c("setosa", "versicolor"), ]
iris_binary$Species <- factor(iris_binary$Species)
# Fit the model
result <- lr(Species ~ Sepal.Length + Sepal.Width, data = iris_binary)
print(result$beta_optimized)
X <- iris_binary[, c("Sepal.Length", "Sepal.Width")]
y <- as.numeric(iris_binary$Species) - 1
result <- lr(X = X, y = y, B = 50, alpha = 0.01)
print(result$beta_optimized)
library(TrainPredict)
lr(am~hp+mpg+wt, data=mtcars, B=50, alpha=0.05)
?lr
?predict_new
?predict_test
?train_test_sampling
install.packages("knitr")
install.packages("rmarkdown")
install.packages("knitr")
install.packages("usethis")
library(usethis)
library(knitr)
library(rmarkdown)
usethis::use_vignette("introduction")
devtools::install_github("hadley/pkgdown")
pkgdown::build_site()
install.packages("xfun")
install.packages("xfun")
pkgdown::build_site()
pkgdown::build_site()
install.packages('xfun')
install.packages("xfun")
pkgdown::build_site()
pkgdown::build_site()
install.packages("yaml")
install.packages("yaml")
pkgdown::build_site()
install.packages("htmltools")
install.packages("htmltools")
pkgdown::build_site()
data("iris")
iris_binary <- iris[iris$Species != "virginica", ]
iris_binary$Species <- as.numeric(iris_binary$Species == "versicolor")
?train_test_sampling
# Setting seed for reproducibility
split_data <- train_test_sampling(iris_binary, train_ratio = 0.8, seed=123)
library(TrainPredict)
# Setting seed for reproducibility
split_data <- train_test_sampling(iris_binary, train_ratio = 0.8, seed=123)
?train_test_sampling
split_data <- train_test_sampling(iris_binary, train_prop = 0.8, return_data=TRUE, seed=123)
split_data <- train_test_sampling(iris_binary, dependent_var="Species", train_prop = 0.8, return_data=TRUE, seed=123)
str(split_data)
# This will give us a list containing two data frames: train with 80% of the observations and test with 20%.
# Extract training and test sets
train_data <- split_data$train
test_data <- split_data$test
# Checking the split
str(train_data)
str(test_data)
# Train logistic regression model
model <- lr(Species ~ Sepal.Length + Sepal.Width, data = train_data)
# Displaying model summary
summary(model)
model
# Train logistic regression model
model <- lr(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width, data = train_data)
model
glmiris<-glm(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width, data = train_data, family=binomial)
sumamry(glmiris)
summary(glmiris)
glmiris<-glm(Species ~ Sepal.Length + Sepal.Width, data = train_data, family=binomial)
summary(glmiris)
head(train_data)
levels(train_data$Species)
unique(train_data$Species)
sum(train_data$Species)
iris[iris$Species != "virginica", ]
iris_binary <- iris
iris_binary$SPecies=='virginica'
iris_binary$Species=='virginica'
iris_binary$Virginica<-iris_binary$Species=='virginica'
dim(iris)
dim(iris_binary)
head(iris_binary)
split_data <- train_test_sampling(iris_binary, dependent_var="Virginica", train_prop = 0.8, return_data=TRUE, seed=123)
# This will give us a list containing two data frames: train with 80% of the observations and test with 20%.
# Extract training and test sets
train_data <- split_data$train
test_data <- split_data$test
# Checking the split
str(train_data)
str(test_data)
# Train logistic regression model
model <- lr(Virginica ~ Sepal.Length + Sepal.Width, data = train_data)
model
glmiris<-glm(Virginica~Sepal.Length+Sepal.Width, data=train_data, family=binomial)
summary(glmiris)
model$beta_optimized
# The model will provide important information like the coefficients of the logistic regression, bootstrap confidence intervals, confusion matrix, prevalence, accuracy, sensitivity, specificity,
model$confusion_matrix
model$accuracy
model$sensitivity
model$specificity
?predict_test
head(test_data)
# Predict on test dataset
test_predictions <- predict_test(model=model, new_data=test_data, dependent_variable_col = "Virginica")
# Display predictions
head(test_predictions)
test_predictions
devtools::document()
library(TrainPredict)
# Predict on test dataset
test_predictions <- predict_test(model=model, new_data=test_data, dependent_variable_col = "Virginica")
# Display predictions
head(test_predictions)
devtools::document()
library(TrainPredict)
# Predict on test dataset
test_predictions <- predict_test(model=model, new_data=test_data, dependent_variable_col = "Virginica")
# Display predictions
head(test_predictions)
sum(test_predictions$predicted_outcomes)
# Creating new data points for prediction
new_data <- data.frame(Sepal.Length = c(5.1, 6.3),
Sepal.Width = c(3.5, 3.0))
# Predicting using the trained model
new_predictions <- predict_new(model, new_data)
new_data
?predict_new
# Predicting using the trained model
new_predictions <- predict_new(data=new_data, model=model, threshold=0.5 )
# Display predictions
new_predictions
pkgdown::build_site()
titanic
data(infert)
head(infert)
length(infert$case)
sum(infert$case)
unique(infert$case)
```r
```r
split_data <- train_test_sampling(mtcars, dependent_var = "am", train_prop = 0.75, seed = 123)
# Extract training and test sets
train_data <- split_data$train
split_data <- train_test_sampling(mtcars, dependent_var = "am", train_prop = 0.75, return_data = TRUE, seed = 123)
# Extract training and test sets
train_data <- split_data$train
test_data <- split_data$test
?lr
# Train a logistic regression model using Sepal.Length and Sepal.Width as predictors
# Variables `hp`, `mpg`, and `wt` will be used as the independent variables to predict `am`.
model <- lr(am ~ hp + mpg + wt, data = train_data, B=100, alpha=0.05)
# Display model summary
print(model$beta_optimized)
print(model$confusion_matrix)
?predict_test
# Make predictions on the test dataset
test_predictions <- predict_test(model = model, new_data = test_data, dependent_variable_col = "am")
# Display predictions
head(test_predictions)
# Display predictions
(test_predictions)
head(mtcars)
mtcars
# Create new data points for prediction
new_data <- data.frame(hp = c(225, 110),
mpg = c(18.9, 25.6),
wt = c(4.485, 1.985))
# Predict using the trained model
new_predictions <- predict_new(data = new_data, model = model, threshold = 0.5)
# Display predictions
print(new_predictions)
# Create new data points for prediction
new_data <- data.frame(hp = c(225, 110),
mpg = c(18.9, 25.6),
wt = c(3.485, 1.985))
# Predict using the trained model
new_predictions <- predict_new(data = new_data, model = model, threshold = 0.5)
# Display predictions
print(new_predictions)
# Create new data points for prediction
new_data <- data.frame(hp = c(225, 110),
mpg = c(15.9, 25.6),
wt = c(3.485, 1.985))
# Predict using the trained model
new_predictions <- predict_new(data = new_data, model = model, threshold = 0.5)
# Display predictions
print(new_predictions)
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
devtools::document()
pkgdown::build_site()
library(TrainPredict)
install_github("AU-R-Programming/Final_Project_Group_7")
devtools::install_github("AU-R-Programming/Final_Project_Group_7")
devtools::install_github("AU-R-Programming/Final_Project_Group_7")
pkgdown::build_site()
library(TrainPredict)
library(TrainPredict)
head(covid)
library(readr)
covid<-read_csv(file="C:/Users/Erick Gutierrez/OneDrive - Auburn University/covid_data.csv", header=T)
covid<-read_csv(file="C:/Users/Erick Gutierrez/OneDrive - Auburn University/covid_data.csv", col_names = =T)
covid<-read_csv(file="C:/Users/Erick Gutierrez/OneDrive - Auburn University/covid_data.csv", col_names =T)
spec(covid)
dim(covid)
head(covid)
covid<-as.data.frame(read_csv(file="C:/Users/Erick Gutierrez/OneDrive - Auburn University/covid_data.csv", col_names =T))
head(covid)
covid<-covid[,-1]
head(covid)
library(TrainPredict)
?test_train_sampling
ttcovid<-train_test_sampling(covid, "Outcome", return_data = TRUE, seed=123)
traincovid<-ttcovid$train
testcovid<-ttcovid$test
covidlr<-lr(Outcome~., data=traincovid, B=50, alpha=0.05)
predict_test(testcovid, covidlr, "Outcome")
covidlr
devtools::document()
pkgdown::build_site()
library(TrainPredict)
devtools::document()
pkgdown::build_site()
devtools::document()
pkgdown::build_site()
devtools::document()
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
?lr
library(TrainPredict)
?lr
?train_test_sampling
devtools::document()
pkgdown::build_site()
devtools::document()
pkgdown::build_site()
