% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/documentation.R
\name{predict_test}
\alias{predict_test}
\title{Predict Outcomes and Evaluate Model Performance on Test Data Set}
\usage{
predict_test(new_data, model, dependent_variable_col)
}
\arguments{
\item{new_data}{A data frame containing the new observations to predict. The column names should match the predictor names in the model.}

\item{model}{A list containing the logistic regression model details. It must have two components:
- `beta_optimized`: A matrix of optimized beta coefficients, including an intercept term.
- `factor_mappings`: A list where each element represents the mapping of levels to numeric values for factor variables.}

\item{dependent_variable_col}{A character string specifying the name or number of the column in `new_data` containing the actual outcomes for evaluation purposes.}
}
\value{
A data frame with two columns:
 - `actual_outcomes`: Actual values of the dependent variable in the test data set.
	- `predicted_outcomes`: Predicted outcomes as "TRUE" or "FALSE".
#'
}
\description{
This function predicts outcomes for a new data set using a provided logistic regression model obtained with function \code{lr} and compares these predictions to the actual outcomes using a confusion matrix. The model must contain optimized beta coefficients (`beta_optimized`) and factor mappings (`factor_mappings`). The function allows for numeric conversion of factor variables in the new data.
}
\details{
This function first converts any factor variables in the new data to numeric values based on the mappings provided in the model. Then, it extracts the predictors required by the model, calculates the log-odds, and converts them to probabilities using the logistic function. Predictions are classified as either "TRUE" or "FALSE" based on a probability threshold of 0.5. A confusion matrix is printed to assess the accuracy of the predictions.
}
\examples{
# Example 1: Using the mtcars dataset with 'am' as the binomial dependent variable.
# First create a training and test sets from original data using function \code{train_test_sampling}
split_data <- train_test_sampling(mtcars, dependent_var = 'am', train_prop = 0.75, return_data = TRUE, seed = 123)
train_data<-split_data$train
test_data<-split_data$test

# For this example we will create a model object using function \code{lr} using the training data, and variable am as the dependent variable.
lrcars<-lr(am~hp+mpg+wt, data=train_data, B=50, alpha=0.05)

# Now that we have created a logistic regression model with the training data, we test the performance of the model in new unseen data stored in the test data set.
results<-predict_test(test_data, lrcars, "am")
head(results)

# Example 2: Predicting outcomes on a binary subset of the Iris dataset
data(iris)
iris_binary <- iris[iris$Species \%in\% c("setosa", "versicolor"), ]
iris_binary$Species <- factor(iris_binary$Species)

# Create a training and test sets from original data using function \code{train_test_sampling}
iris_binary_samples<-train_test_sampling(iris_binary, dependent_var="Species", train_prop=0.75, return_data=TRUE, seed=123)
iris_train<-iris_binary_samples$train
iris_test<-iris_binary_samples$test

# Fit a logistic regression model using function \code{lr}
model <- lr(Species ~ Sepal.Length + Sepal.Width, data = iris_train)

# Predict outcomes on test data
predictions <- predict_test(new_data = iris_test, model = model, dependent_variable_col = "Species")
head(predictions)

}
\seealso{
\code{\link{lr}}, \code{\link{train_test_sample}}
}
